{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Завдання\n",
    "Проведіть класифікацію на основі датасету UCI ML Breast Cancer Wisconsin, використовуючи вказані у презентації моделі бустингу, беггінгу та стекінгу. Змініть їх параметри наступним чином:\n",
    "\n",
    "у StackingClassifier як базові алгоритми встановіть LogisticRegression та DecisionTreeClassifier, як фінальну модель – SVC;\n",
    "у BaggingClassifier як базовий алгоритм встановіть DecisionTreeClassifier;\n",
    "у AdaBoostClassifier як базовий алгоритм встановіть LogisticRegression\n",
    "у XGBСlassifier як базовий алгоритм (booster) встановіть ‘gbtree’.\n",
    "У зведеній таблиці порівняйте результати класифікацій, наведених у коді, із класифікаціями, що отримані вами.\n",
    "\n",
    "## Рішення"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# імпорт бібліотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Підготовка даних:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# завантаження датасету\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)\n",
    "\n",
    "# перетворення значень міток класів M та B у числові значення 1 та 0 відповідно\n",
    "data[1] = np.where(data[1] == 'M', 1, 0)\n",
    "\n",
    "# визначення ознак та міток класів\n",
    "X = data.iloc[:, 2:]\n",
    "y = data.iloc[:, 1]\n",
    "\n",
    "# розділення на тренувальний та тестовий набори\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2023)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Побудова базових моделей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Стекінг\n",
    "estimators = [('lr', LogisticRegression(max_iter=10000)), ('sgc', SGDClassifier())]\n",
    "sc = StackingClassifier(estimators=estimators, final_estimator=DecisionTreeClassifier())\n",
    "sc.fit(X_train, y_train)\n",
    "y_pred = sc.predict(X_test)\n",
    "sc_accuracy = accuracy_score(y_test, y_pred)\n",
    "sc_recall = recall_score(y_test, y_pred)\n",
    "sc_precision = precision_score(y_test, y_pred)\n",
    "sc_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Беггінг\n",
    "bc = BaggingClassifier(estimator=LogisticRegression(max_iter=10000), n_estimators=100, random_state=2023)\n",
    "bc.fit(X_train, y_train)\n",
    "y_pred = bc.predict(X_test)\n",
    "bc_accuracy = accuracy_score(y_test, y_pred)\n",
    "bc_recall = recall_score(y_test, y_pred)\n",
    "bc_precision = precision_score(y_test, y_pred)\n",
    "bc_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# AdaBoostClassifier бустинг\n",
    "abc = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=6), n_estimators=100, random_state=2023)\n",
    "abc.fit(X_train, y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "abc_accuracy = accuracy_score(y_test, y_pred)\n",
    "abc_recall = recall_score(y_test, y_pred)\n",
    "abc_precision = precision_score(y_test, y_pred)\n",
    "abc_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# XGBClassifier\n",
    "xgb = XGBClassifier(booster='gblinear', learning_rate=0.02, n_estimators=100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "xgb_recall = recall_score(y_test, y_pred)\n",
    "xgb_precision = precision_score(y_test, y_pred)\n",
    "xgb_f1 = f1_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ### Побудова моделей зі зміною параметрів"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Змінені параметри\n",
    "# StackingClassifier\n",
    "estimators = [('lg', LogisticRegression(max_iter=10000)), ('dtc', DecisionTreeClassifier())]\n",
    "sc = StackingClassifier(estimators=estimators, final_estimator=SVC())\n",
    "sc.fit(X_train, y_train)\n",
    "y_pred = sc.predict(X_test)\n",
    "sc_accuracy_mod = accuracy_score(y_test, y_pred)\n",
    "sc_recall_mod = recall_score(y_test, y_pred)\n",
    "sc_precision_mod = precision_score(y_test, y_pred)\n",
    "sc_f1_mod = f1_score(y_test, y_pred)\n",
    "\n",
    "# BaggingClassifier\n",
    "bc = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=5), n_estimators=50)\n",
    "bc.fit(X_train, y_train)\n",
    "y_pred = bc.predict(X_test)\n",
    "bc_accuracy_mod = accuracy_score(y_test, y_pred)\n",
    "bc_recall_mod = recall_score(y_test, y_pred)\n",
    "bc_precision_mod = precision_score(y_test, y_pred)\n",
    "bc_f1_mod = f1_score(y_test, y_pred)\n",
    "\n",
    "# AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(estimator=LogisticRegression(C=0.5, penalty='l2', max_iter=1000), n_estimators=100, learning_rate=0.1)\n",
    "abc.fit(X_train, y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "abc_accuracy_mod = accuracy_score(y_test, y_pred)\n",
    "abc_recall_mod = recall_score(y_test, y_pred)\n",
    "abc_precision_mod = precision_score(y_test, y_pred)\n",
    "abc_f1_mod = f1_score(y_test, y_pred)\n",
    "\n",
    "# XGBClassifier\n",
    "xgb = XGBClassifier(booster='gbtree')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "xgb_accuracy_mod = accuracy_score(y_test, y_pred)\n",
    "xgb_recall_mod = recall_score(y_test, y_pred)\n",
    "xgb_precision_mod = precision_score(y_test, y_pred)\n",
    "xgb_f1_mod = f1_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Зведена таблиця результатів"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порівняння ефективності моделей\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Модель   Параметри  Точність  Чутливість  Специфічність  \\\n0  StackingClassifier    з лекції  0.941520    0.901639       0.932203   \n1  StackingClassifier  з завдання  0.970760    0.934426       0.982759   \n2   BaggingClassifier    з лекції  0.970760    0.950820       0.966667   \n3   BaggingClassifier  з завдання  0.947368    0.934426       0.919355   \n4  AdaBoostClassifier    з лекції  0.929825    0.918033       0.888889   \n5  AdaBoostClassifier  з завдання  0.970760    0.950820       0.888889   \n6       XGBClassifier    з лекції  0.929825    0.819672       0.980392   \n7       XGBClassifier  з завдання  0.964912    0.950820       0.950820   \n\n   F1-score  \n0  0.916667  \n1  0.957983  \n2  0.958678  \n3  0.926829  \n4  0.903226  \n5  0.958678  \n6  0.892857  \n7  0.950820  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Модель</th>\n      <th>Параметри</th>\n      <th>Точність</th>\n      <th>Чутливість</th>\n      <th>Специфічність</th>\n      <th>F1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>StackingClassifier</td>\n      <td>з лекції</td>\n      <td>0.941520</td>\n      <td>0.901639</td>\n      <td>0.932203</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>StackingClassifier</td>\n      <td>з завдання</td>\n      <td>0.970760</td>\n      <td>0.934426</td>\n      <td>0.982759</td>\n      <td>0.957983</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BaggingClassifier</td>\n      <td>з лекції</td>\n      <td>0.970760</td>\n      <td>0.950820</td>\n      <td>0.966667</td>\n      <td>0.958678</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BaggingClassifier</td>\n      <td>з завдання</td>\n      <td>0.947368</td>\n      <td>0.934426</td>\n      <td>0.919355</td>\n      <td>0.926829</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AdaBoostClassifier</td>\n      <td>з лекції</td>\n      <td>0.929825</td>\n      <td>0.918033</td>\n      <td>0.888889</td>\n      <td>0.903226</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AdaBoostClassifier</td>\n      <td>з завдання</td>\n      <td>0.970760</td>\n      <td>0.950820</td>\n      <td>0.888889</td>\n      <td>0.958678</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>XGBClassifier</td>\n      <td>з лекції</td>\n      <td>0.929825</td>\n      <td>0.819672</td>\n      <td>0.980392</td>\n      <td>0.892857</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>XGBClassifier</td>\n      <td>з завдання</td>\n      <td>0.964912</td>\n      <td>0.950820</td>\n      <td>0.950820</td>\n      <td>0.950820</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Створення DataFrame з результатами класифікації\n",
    "results_df = pd.DataFrame({\n",
    "    'Модель': ['StackingClassifier', 'StackingClassifier', 'BaggingClassifier', 'BaggingClassifier', 'AdaBoostClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'XGBClassifier'],\n",
    "    'Параметри': ['з лекції', 'з завдання', 'з лекції', 'з завдання', 'з лекції', 'з завдання', 'з лекції', 'з завдання'],\n",
    "    'Точність': [sc_accuracy, sc_accuracy_mod, bc_accuracy, bc_accuracy_mod, abc_accuracy, abc_accuracy_mod, xgb_accuracy, xgb_accuracy_mod],\n",
    "    'Чутливість': [sc_recall, sc_recall_mod, bc_recall, bc_recall_mod, abc_recall, abc_recall_mod, xgb_recall, xgb_recall_mod],\n",
    "    'Специфічність': [sc_precision, sc_precision_mod, bc_precision, bc_precision_mod, abc_precision, abc_precision, xgb_precision, xgb_precision_mod],\n",
    "    'F1-score': [sc_f1, sc_f1_mod, bc_f1, bc_f1_mod, abc_f1, abc_f1_mod, xgb_f1, xgb_f1_mod]\n",
    "})\n",
    "\n",
    "# Відображення зведеної таблиці\n",
    "print('Порівняння ефективності моделей')\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приріст/падіння ефективності моделей, %\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               Точність  Чутливість  Специфічність  F1-score\nМодель             Параметри                                                \nXGBClassifier      з завдання  3.508772   13.114754      -2.957248  5.796253\nAdaBoostClassifier з завдання  4.093567    3.278689       0.000000  5.545188\nStackingClassifier з завдання  2.923977    3.278689       5.055523  4.131653\nBaggingClassifier  з завдання -2.339181   -1.639344      -4.731183 -3.184842",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Точність</th>\n      <th>Чутливість</th>\n      <th>Специфічність</th>\n      <th>F1-score</th>\n    </tr>\n    <tr>\n      <th>Модель</th>\n      <th>Параметри</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>XGBClassifier</th>\n      <th>з завдання</th>\n      <td>3.508772</td>\n      <td>13.114754</td>\n      <td>-2.957248</td>\n      <td>5.796253</td>\n    </tr>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <th>з завдання</th>\n      <td>4.093567</td>\n      <td>3.278689</td>\n      <td>0.000000</td>\n      <td>5.545188</td>\n    </tr>\n    <tr>\n      <th>StackingClassifier</th>\n      <th>з завдання</th>\n      <td>2.923977</td>\n      <td>3.278689</td>\n      <td>5.055523</td>\n      <td>4.131653</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <th>з завдання</th>\n      <td>-2.339181</td>\n      <td>-1.639344</td>\n      <td>-4.731183</td>\n      <td>-3.184842</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Приріст/падіння ефективності моделей, %')\n",
    "results_df.set_index(['Модель','Параметри']) \\\n",
    "    .diff() \\\n",
    "    .filter(regex='з завдання', axis=0) \\\n",
    "    .sort_values(['F1-score'], ascending=False) \\\n",
    "    .select_dtypes(include=['number']) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Висновок\n",
    "1. Кращими моделями класифікації у такому випадку є Bagging (з лекції) та AdaBoost (з завдання).\n",
    "2. Найбільший приріст точності через модифікацію параметрів моделі зазнала XGB.\n",
    "3. Модель Bagging навпаки зазнала найбільшої втрати з точки зору ефективності.\n",
    "4. Загалом, зміна параметрів може покращити результати, але важливо не забувати про підбір гіперпараметрів шляхом випадкового пошуку або пошуку по сітці."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
